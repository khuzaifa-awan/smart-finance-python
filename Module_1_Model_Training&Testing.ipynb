{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "48ec8342",
        "outputId": "b0fc03b1-0780-45b4-d141-cf9f5b10985e"
      },
      "source": [
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "kaggle_dir = '/root/.kaggle'\n",
        "os.makedirs(kaggle_dir, exist_ok=True)\n",
        "\n",
        "# Upload the kaggle.json file\n",
        "print(\"Please upload your kaggle.json file:\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Move the uploaded file to the correct directory and set permissions\n",
        "for fn in uploaded.keys():\n",
        "    !mv \"$fn\" \"{kaggle_dir}/kaggle.json\"\n",
        "    !chmod 600 \"{kaggle_dir}/kaggle.json\"\n",
        "    print(f\"Uploaded and configured {fn}\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please upload your kaggle.json file:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d457e472-6934-46a8-8c0a-99d74bdf7892\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-d457e472-6934-46a8-8c0a-99d74bdf7892\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "Uploaded and configured kaggle.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import random\n",
        "import warnings\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# ---------------- CONFIG ----------------\n",
        "DATA_DIR = \"/content/data\"\n",
        "KAGGLE_DATASET = \"shriyashjagtap/indian-personal-finance-and-spending-habits\"\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)\n",
        "random.seed(RANDOM_SEED)\n",
        "\n",
        "# Domain hyperparameters (tuneable)\n",
        "MIN_MONTHLY_INCOME = 15_000\n",
        "MAX_MONTHLY_INCOME = 500_000\n",
        "EXPENSE_TO_INCOME_RATIO = 0.65\n",
        "SAVINGS_RATE_RANGE = (0.05, 0.25)\n",
        "MAX_SAVINGS_FRACTION = 0.5         # fraction of disposable income users can realistically save\n",
        "MIN_PRACTICAL_SAVE = 500           # smallest practical monthly save shown to users\n",
        "SYNTHETIC_SAVINGS_CAP_MULTIPLE = 24  # cap synthetic savings at income * multiple\n",
        "\n",
        "os.makedirs(DATA_DIR, exist_ok=True)\n",
        "\n",
        "# ---------------- HELPERS ----------------\n",
        "def download_kaggle_dataset(dataset_ref=KAGGLE_DATASET, out_dir=DATA_DIR):\n",
        "    try:\n",
        "        from kaggle.api.kaggle_api_extended import KaggleApi\n",
        "    except Exception as e:\n",
        "        print(\"[kaggle] Kaggle API not available:\", e)\n",
        "        return False\n",
        "    try:\n",
        "        api = KaggleApi()\n",
        "        api.authenticate()\n",
        "        print(\"[kaggle] downloading dataset:\", dataset_ref)\n",
        "        api.dataset_download_files(dataset_ref, path=out_dir, unzip=True, quiet=False)\n",
        "        print(\"[kaggle] download + unzip done\")\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(\"[kaggle] download failed:\", e)\n",
        "        return False\n",
        "\n",
        "def find_first_csv(data_dir=DATA_DIR):\n",
        "    files = glob.glob(os.path.join(data_dir, \"**\", \"*.csv\"), recursive=True)\n",
        "    if not files:\n",
        "        return None\n",
        "    for f in files:\n",
        "        lf = f.lower()\n",
        "        if any(k in lf for k in (\"finance\", \"spending\", \"data\", \"personal\")):\n",
        "            return f\n",
        "    return sorted(files, key=lambda p: os.path.getsize(p), reverse=True)[0]\n",
        "\n",
        "def find_cols_by_tokens(cols, tokens):\n",
        "    return [c for c in cols if any(tok in c.lower() for tok in tokens)]\n",
        "\n",
        "def is_pct_col(name, series):\n",
        "    lname = name.lower()\n",
        "    if \"percent\" in lname or \"percentage\" in lname or lname.endswith(\"_pct\"):\n",
        "        return True\n",
        "    s = pd.to_numeric(series, errors=\"coerce\").dropna()\n",
        "    if s.empty:\n",
        "        return False\n",
        "    if s.max() <= 100 and s.median() <= 100:\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "def smart_scale(series, name):\n",
        "    s = pd.to_numeric(series, errors=\"coerce\")\n",
        "    non_na = s.dropna()\n",
        "    if non_na.empty:\n",
        "        return s.fillna(0)\n",
        "    if is_pct_col(name, s):\n",
        "        return s.fillna(0)\n",
        "    med = non_na.median()\n",
        "    mx = non_na.max()\n",
        "    if med < 100 and \"age\" not in name.lower() and \"count\" not in name.lower() and \"depend\" not in name.lower():\n",
        "        if mx < 100:\n",
        "            return s.fillna(0)\n",
        "        scaled = s * 1000\n",
        "        print(f\"[scale] scaled '{name}' median {med:.2f} -> {scaled.dropna().median():.2f}\")\n",
        "        return scaled.fillna(0)\n",
        "    if 100 <= med <= 1000:\n",
        "        print(f\"[info] ambiguous units for '{name}' median {med:.1f} — left as-is.\")\n",
        "        return s.fillna(0)\n",
        "    return s.fillna(0)\n",
        "\n",
        "# ---------------- MAIN ----------------\n",
        "def main():\n",
        "    print(\"=== pipeline start ===\")\n",
        "    csv_path = find_first_csv()\n",
        "    if csv_path is None:\n",
        "        print(\"[info] no CSV found locally -> trying Kaggle download\")\n",
        "        ok = download_kaggle_dataset()\n",
        "        if ok:\n",
        "            csv_path = find_first_csv()\n",
        "    if csv_path is None:\n",
        "        raise FileNotFoundError(\"No CSV found in DATA_DIR and Kaggle failed. Put dataset CSV in /content/data\")\n",
        "    print(\"[info] using dataset:\", csv_path)\n",
        "\n",
        "    raw = pd.read_csv(csv_path, low_memory=False)\n",
        "    raw.columns = [c.strip().lower().replace(\" \", \"_\") for c in raw.columns]\n",
        "    print(\"[info] raw shape:\", raw.shape)\n",
        "\n",
        "    # conservative detection\n",
        "    potential_prefix = \"potential_savings\"\n",
        "    potential_cols = [c for c in raw.columns if c.startswith(potential_prefix)]\n",
        "    expense_tokens = [\"rent\",\"loan\",\"insurance\",\"groceries\",\"transport\",\"eating_out\",\"entertainment\",\"utilities\",\"healthcare\",\"education\",\"misc\",\"miscellaneous\"]\n",
        "    income_tokens = [\"income\",\"salary\",\"monthly_income\",\"earn\"]\n",
        "    savings_tokens = [\"current_savings\",\"current_saving\",\"savings\",\"saving\"]\n",
        "\n",
        "    expense_candidates = find_cols_by_tokens(raw.columns, expense_tokens)\n",
        "    # exclude potential/desired/percentage columns from expenses\n",
        "    expense_cols = [c for c in expense_candidates if not (c in potential_cols or \"potential\" in c.lower() or \"desired\" in c.lower() or \"percentage\" in c.lower())]\n",
        "    income_cols = find_cols_by_tokens(raw.columns, income_tokens)\n",
        "    desired_cols = [c for c in raw.columns if \"desired_saving\" in c or \"desired_savings\" in c]\n",
        "    savings_candidates = [c for c in raw.columns if any(tok in c for tok in savings_tokens) and not any(x in c for x in (\"desired\",\"potential\",\"percentage\"))]\n",
        "    demographic_cols = find_cols_by_tokens(raw.columns, [\"age\",\"dependents\",\"occupation\",\"city_tier\",\"education\",\"gender\"])\n",
        "\n",
        "    print(\"[info] expense_cols:\", expense_cols)\n",
        "    print(\"[info] income_cols:\", income_cols)\n",
        "    print(\"[info] potential_savings:\", potential_cols)\n",
        "    print(\"[info] savings_candidates:\", savings_candidates)\n",
        "    print(\"[info] demographic_cols:\", demographic_cols)\n",
        "\n",
        "    # scaling candidates (but skip potential/desired/percentage)\n",
        "    scale_candidates = list(set(income_cols + expense_cols + potential_cols + desired_cols + savings_candidates))\n",
        "    skip_prefixes = ['potential_savings', 'desired_savings', 'desired_saving']\n",
        "    def should_autoscale(col):\n",
        "        lname = col.lower()\n",
        "        if any(lname.startswith(p) for p in skip_prefixes):\n",
        "            return False\n",
        "        if 'percentage' in lname or 'percent' in lname:\n",
        "            return False\n",
        "        return True\n",
        "\n",
        "    df = raw.copy()\n",
        "    for col in sorted(scale_candidates):\n",
        "        if col in df.columns:\n",
        "            if should_autoscale(col):\n",
        "                df[col] = smart_scale(df[col], col)\n",
        "            else:\n",
        "                df[col] = pd.to_numeric(df[col], errors=\"coerce\").fillna(0)\n",
        "                print(f\"[skip-scale] kept '{col}' raw\")\n",
        "\n",
        "    # income consolidation\n",
        "    if \"income\" in df.columns:\n",
        "        df[\"income\"] = pd.to_numeric(df[\"income\"], errors=\"coerce\")\n",
        "    elif income_cols:\n",
        "        df[\"income\"] = pd.to_numeric(df[income_cols[0]], errors=\"coerce\")\n",
        "    else:\n",
        "        print(\"[gen] generating synthetic income\")\n",
        "        df[\"income\"] = np.exp(np.random.uniform(np.log(MIN_MONTHLY_INCOME), np.log(MAX_MONTHLY_INCOME), size=len(df))).round(0)\n",
        "    df[\"income\"] = df[\"income\"].fillna(df[\"income\"].median()).clip(lower=MIN_MONTHLY_INCOME, upper=MAX_MONTHLY_INCOME)\n",
        "\n",
        "    # total_expenses\n",
        "    if expense_cols:\n",
        "        for c in expense_cols:\n",
        "            df[c] = pd.to_numeric(df[c], errors=\"coerce\").fillna(0)\n",
        "        df[\"total_expenses\"] = df[expense_cols].sum(axis=1, skipna=True)\n",
        "    else:\n",
        "        ratio = np.clip(np.random.normal(EXPENSE_TO_INCOME_RATIO, 0.1, len(df)), 0.35, 0.95)\n",
        "        df[\"total_expenses\"] = (df[\"income\"] * ratio).round(0)\n",
        "\n",
        "    # recompute disposable_income deterministically (drop raw if present)\n",
        "    if \"disposable_income\" in df.columns:\n",
        "        try:\n",
        "            df.drop(columns=[\"disposable_income\"], inplace=True)\n",
        "        except Exception:\n",
        "            pass\n",
        "    df[\"disposable_income\"] = (df[\"income\"] - df[\"total_expenses\"]).fillna(0).clip(lower=0)\n",
        "\n",
        "    # current_savings: prefer real column if sensible\n",
        "    chosen_sav = None\n",
        "    for c in savings_candidates:\n",
        "        if c in df.columns:\n",
        "            med = pd.to_numeric(df[c], errors=\"coerce\").dropna().median()\n",
        "            if pd.notna(med) and med > 100:\n",
        "                chosen_sav = c\n",
        "                break\n",
        "\n",
        "    if chosen_sav:\n",
        "        df[\"current_savings\"] = pd.to_numeric(df[chosen_sav], errors=\"coerce\").fillna(0)\n",
        "        df[\"savings_is_synthetic\"] = False\n",
        "        print(f\"[use] using '{chosen_sav}' for current_savings\")\n",
        "    else:\n",
        "        # generate synthetic savings and flag them\n",
        "        df[\"savings_is_synthetic\"] = True\n",
        "        sav_ratio = np.random.uniform(SAVINGS_RATE_RANGE[0], SAVINGS_RATE_RANGE[1], size=len(df))\n",
        "        months_saved = np.random.uniform(3, 36, size=len(df))\n",
        "        df[\"current_savings\"] = (df[\"income\"] * sav_ratio * months_saved).round(0)\n",
        "        print(\"[gen] generated synthetic current_savings for all rows (flagged)\")\n",
        "\n",
        "    # CAP synthetic savings to reasonable multiple\n",
        "    cap_mult = SYNTHETIC_SAVINGS_CAP_MULTIPLE\n",
        "    mask_synth = df[\"savings_is_synthetic\"] == True\n",
        "    if mask_synth.any():\n",
        "        df.loc[mask_synth, \"current_savings\"] = df.loc[mask_synth, \"current_savings\"].clip(upper=(df.loc[mask_synth, \"income\"] * cap_mult))\n",
        "        print(f\"[cap] capped synthetic current_savings at income * {cap_mult}\")\n",
        "\n",
        "    df[\"current_savings\"] = df[\"current_savings\"].clip(lower=0)\n",
        "\n",
        "    # total potential savings aggregation (kept raw as monthly-scale by default)\n",
        "    if potential_cols:\n",
        "        for c in potential_cols:\n",
        "            df[c] = pd.to_numeric(df[c], errors=\"coerce\").fillna(0)\n",
        "        df[\"total_potential_savings\"] = df[potential_cols].sum(axis=1, skipna=True)\n",
        "    else:\n",
        "        df[\"total_potential_savings\"] = 0\n",
        "\n",
        "    # goals\n",
        "    df[\"months_remaining\"] = np.random.choice([6,12,18,24,36,48,60], size=len(df), p=[0.10,0.20,0.25,0.20,0.15,0.07,0.03])\n",
        "    multipliers = {6:1.5,12:3,18:4.5,24:6,36:9,48:12,60:15}\n",
        "    df[\"goal_target_amount\"] = df.apply(lambda r: r[\"income\"] * multipliers.get(int(r[\"months_remaining\"]),4) * np.random.uniform(0.8,1.2), axis=1)\n",
        "    if \"desired_savings\" in df.columns:\n",
        "        ds = pd.to_numeric(df[\"desired_savings\"], errors=\"coerce\").fillna(0)\n",
        "        if ds.median() > 1000:\n",
        "            use_ds = (ds > df[\"current_savings\"] * 1.2) & (ds < df[\"income\"] * 60)\n",
        "            df.loc[use_ds, \"goal_target_amount\"] = ds.loc[use_ds]\n",
        "            print(f\"[use] applied 'desired_savings' as goal for {use_ds.sum()} rows\")\n",
        "\n",
        "    df[\"goal_target_amount\"] = df[\"goal_target_amount\"].clip(upper=df[\"income\"] * 60)\n",
        "\n",
        "    # monthly requirements + feasibility\n",
        "    df[\"monthly_saving_required\"] = ((df[\"goal_target_amount\"] - df[\"current_savings\"]) / df[\"months_remaining\"]).clip(lower=0)\n",
        "    df[\"max_feasible_monthly_saving\"] = (df[\"disposable_income\"] * MAX_SAVINGS_FRACTION).fillna(0)\n",
        "    df[\"monthly_saving_label\"] = np.minimum(df[\"monthly_saving_required\"], df[\"max_feasible_monthly_saving\"])\n",
        "    # keep raw copy\n",
        "    df[\"monthly_saving_label_raw\"] = df[\"monthly_saving_label\"].copy()\n",
        "\n",
        "    # derived metrics\n",
        "    df[\"expense_ratio\"] = (df[\"total_expenses\"] / df[\"income\"]).replace([np.inf, -np.inf], np.nan).fillna(EXPENSE_TO_INCOME_RATIO)\n",
        "    df[\"savings_rate\"] = (df[\"disposable_income\"] / df[\"income\"]).clip(0,1).fillna(0)\n",
        "    df[\"financial_health_score\"] = (\n",
        "        (1 - df[\"expense_ratio\"]) * 0.4 +\n",
        "        df[\"savings_rate\"] * 0.3 +\n",
        "        (df[\"current_savings\"] / (df[\"income\"] * 3 + 1e-9)) * 0.3\n",
        "    ).clip(0,1)\n",
        "\n",
        "    # canonical recompute & audit\n",
        "    recomputed_disp = (df[\"income\"] - df[\"total_expenses\"]).fillna(0).clip(lower=0)\n",
        "    mismatch_mask = (df[\"disposable_income\"] != recomputed_disp) & (recomputed_disp > 0)\n",
        "    if mismatch_mask.sum() > 0:\n",
        "        print(f\"[audit] disposable mismatch rows: {mismatch_mask.sum()} -> saving disposable_mismatch_debug.csv\")\n",
        "        df.loc[mismatch_mask, [\"income\",\"total_expenses\",\"disposable_income\"]].to_csv(os.path.join(DATA_DIR, \"disposable_mismatch_debug.csv\"), index=False)\n",
        "    df[\"disposable_income\"] = recomputed_disp\n",
        "\n",
        "    # achievable_by_cutting & suggested plan\n",
        "    df[\"achievable_by_cutting\"] = (df[\"total_potential_savings\"] >= df[\"monthly_saving_required\"]).astype(int)\n",
        "\n",
        "    def suggest_plan(r):\n",
        "        if r[\"current_savings\"] >= r[\"goal_target_amount\"]:\n",
        "            return 0.0\n",
        "        if r[\"achievable_by_cutting\"] == 1:\n",
        "            return float(r[\"monthly_saving_required\"])\n",
        "        if r[\"max_feasible_monthly_saving\"] >= MIN_PRACTICAL_SAVE:\n",
        "            return float(r[\"max_feasible_monthly_saving\"])\n",
        "        return np.nan\n",
        "\n",
        "    df[\"suggested_monthly_plan\"] = df.apply(suggest_plan, axis=1)\n",
        "\n",
        "    # goal_achieved: current_savings >= target OR (label==0 and tiny requirement)\n",
        "    df[\"goal_achieved\"] = ((df[\"current_savings\"] >= df[\"goal_target_amount\"]) | (df[\"monthly_saving_label\"] == 0)).astype(int)\n",
        "\n",
        "    # difficulty bucket\n",
        "    def bucket(r):\n",
        "        if r[\"goal_achieved\"] == 1:\n",
        "            return \"achieved\"\n",
        "        if r[\"achievable_by_cutting\"] == 1:\n",
        "            return \"achievable_by_cutting\"\n",
        "        rf = r[\"monthly_saving_required\"]/(r[\"disposable_income\"]+1e-9) if r[\"disposable_income\"]>0 else np.nan\n",
        "        if np.isnan(rf):\n",
        "            return \"unknown\"\n",
        "        if rf <= 0.2: return \"easy\"\n",
        "        if rf <= 0.5: return \"moderate\"\n",
        "        if r[\"max_feasible_monthly_saving\"] >= MIN_PRACTICAL_SAVE: return \"hard\"\n",
        "        return \"structural_change_needed\"\n",
        "\n",
        "    df[\"difficulty_bucket\"] = df.apply(bucket, axis=1)\n",
        "\n",
        "    # Fix label semantics for rows that are achievable_by_cutting but label==0 (make training label numeric)\n",
        "    mask_fix = (df[\"monthly_saving_label\"] == 0) & (df[\"achievable_by_cutting\"] == 1)\n",
        "    fix_count = int(mask_fix.sum())\n",
        "    if fix_count > 0:\n",
        "        print(f\"[fix] {fix_count} label==0 & achievable_by_cutting -> setting monthly_saving_label = monthly_saving_required\")\n",
        "        df.loc[mask_fix, \"monthly_saving_label\"] = df.loc[mask_fix, \"monthly_saving_required\"]\n",
        "\n",
        "    # small labels keep zero if not achievable_by_cutting\n",
        "    small_mask = (df[\"monthly_saving_label\"] < MIN_PRACTICAL_SAVE) & (df[\"achievable_by_cutting\"] == 0)\n",
        "    df.loc[small_mask, \"monthly_saving_label\"] = 0.0\n",
        "\n",
        "    # Final caps / fills\n",
        "    df = df.fillna(0)\n",
        "    df[\"income\"] = df[\"income\"].clip(lower=MIN_MONTHLY_INCOME, upper=MAX_MONTHLY_INCOME)\n",
        "    df[\"total_expenses\"] = df[\"total_expenses\"].clip(lower=0, upper=df[\"income\"] * 0.95)\n",
        "    df[\"disposable_income\"] = (df[\"income\"] - df[\"total_expenses\"]).clip(lower=0)\n",
        "\n",
        "    # Save processed & features\n",
        "    processed_cols = [\n",
        "        \"income\",\"total_expenses\",\"disposable_income\",\"current_savings\",\n",
        "        \"goal_target_amount\",\"months_remaining\",\"monthly_saving_label\",\n",
        "        \"monthly_saving_required\",\"max_feasible_monthly_saving\",\"monthly_saving_label_raw\",\n",
        "        \"expense_ratio\",\"savings_rate\",\"financial_health_score\",\"goal_achieved\",\n",
        "        \"total_potential_savings\",\"achievable_by_cutting\",\"suggested_monthly_plan\",\"difficulty_bucket\",\n",
        "        \"savings_is_synthetic\"\n",
        "    ]\n",
        "    for c in demographic_cols:\n",
        "        if c in df.columns and c not in processed_cols:\n",
        "            processed_cols.append(c)\n",
        "\n",
        "    processed_df = df[processed_cols].copy()\n",
        "    processed_out = os.path.join(DATA_DIR, \"processed_finance_dataset.csv\")\n",
        "    features_out = os.path.join(DATA_DIR, \"processed_finance_dataset_features.csv\")\n",
        "    processed_df.to_csv(processed_out, index=False)\n",
        "    df.to_csv(features_out, index=False)\n",
        "    print(\"[save] wrote processed and features\")\n",
        "\n",
        "    # Save audits\n",
        "    prob_zero_mask = (processed_df[\"monthly_saving_label\"] == 0) & (processed_df[\"monthly_saving_required\"] >= MIN_PRACTICAL_SAVE)\n",
        "    if prob_zero_mask.any():\n",
        "        processed_df.loc[prob_zero_mask].to_csv(os.path.join(DATA_DIR, \"problem_rows_zero_label.csv\"), index=False)\n",
        "        print(\"[audit] wrote problem_rows_zero_label.csv\")\n",
        "\n",
        "    if \"total_potential_savings\" in df.columns:\n",
        "        susp_mask = df[\"total_potential_savings\"] > df[\"income\"] * 12\n",
        "        if susp_mask.any():\n",
        "            df.loc[susp_mask].to_csv(os.path.join(DATA_DIR, \"potential_savings_suspicious.csv\"), index=False)\n",
        "            print(\"[audit] wrote potential_savings_suspicious.csv\")\n",
        "\n",
        "    # train/test split (stratify on difficulty_bucket if meaningful)\n",
        "    strat = df[\"difficulty_bucket\"] if df[\"difficulty_bucket\"].nunique() > 1 else df[\"goal_achieved\"] if df[\"goal_achieved\"].nunique() > 1 else None\n",
        "    if strat is not None:\n",
        "        tr, te = train_test_split(df, test_size=0.2, random_state=RANDOM_SEED, stratify=strat)\n",
        "    else:\n",
        "        tr, te = train_test_split(df, test_size=0.2, random_state=RANDOM_SEED)\n",
        "    tr.to_csv(os.path.join(DATA_DIR, \"train.csv\"), index=False)\n",
        "    te.to_csv(os.path.join(DATA_DIR, \"test.csv\"), index=False)\n",
        "    print(\"[save] wrote train/test\")\n",
        "\n",
        "    # Summary\n",
        "    print(\"\\n=== pipeline summary ===\")\n",
        "    print(\"rows:\", len(df))\n",
        "    print(\"income range: {:.0f} - {:.0f}\".format(df[\"income\"].min(), df[\"income\"].max()))\n",
        "    print(\"avg monthly_saving_label: {:.0f}\".format(df[\"monthly_saving_label\"].mean()))\n",
        "    print(\"goals achieved:\", int(df[\"goal_achieved\"].sum()), \"({:.1f}%)\".format(df[\"goal_achieved\"].mean()*100))\n",
        "    print(\"fraction label==0: {:.2%}\".format((df[\"monthly_saving_label\"]==0).mean()))\n",
        "    print(\"difficulty counts:\\n\", df[\"difficulty_bucket\"].value_counts())\n",
        "\n",
        "    print(\"\\nAudit files: disposable_mismatch_debug.csv, problem_rows_zero_label.csv, potential_savings_suspicious.csv (if created)\")\n",
        "    print(\"=== pipeline end ===\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7l8LS8oPohzS",
        "outputId": "06ee943a-cf7f-420e-895a-4bd8dee02304"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== pipeline start ===\n",
            "[info] using dataset: /content/data/data.csv\n",
            "[info] raw shape: (20000, 27)\n",
            "[info] expense_cols: ['rent', 'loan_repayment', 'insurance', 'groceries', 'transport', 'eating_out', 'entertainment', 'utilities', 'healthcare', 'education', 'miscellaneous']\n",
            "[info] income_cols: ['income', 'disposable_income']\n",
            "[info] potential_savings: ['potential_savings_groceries', 'potential_savings_transport', 'potential_savings_eating_out', 'potential_savings_entertainment', 'potential_savings_utilities', 'potential_savings_healthcare', 'potential_savings_education', 'potential_savings_miscellaneous']\n",
            "[info] savings_candidates: []\n",
            "[info] demographic_cols: ['age', 'dependents', 'occupation', 'city_tier', 'education', 'desired_savings_percentage', 'potential_savings_education']\n",
            "[skip-scale] kept 'desired_savings' raw\n",
            "[skip-scale] kept 'desired_savings_percentage' raw\n",
            "[scale] scaled 'loan_repayment' median 0.00 -> 0.00\n",
            "[info] ambiguous units for 'miscellaneous' median 579.1 — left as-is.\n",
            "[skip-scale] kept 'potential_savings_eating_out' raw\n",
            "[skip-scale] kept 'potential_savings_education' raw\n",
            "[skip-scale] kept 'potential_savings_entertainment' raw\n",
            "[skip-scale] kept 'potential_savings_groceries' raw\n",
            "[skip-scale] kept 'potential_savings_healthcare' raw\n",
            "[skip-scale] kept 'potential_savings_miscellaneous' raw\n",
            "[skip-scale] kept 'potential_savings_transport' raw\n",
            "[skip-scale] kept 'potential_savings_utilities' raw\n",
            "[gen] generated synthetic current_savings for all rows (flagged)\n",
            "[cap] capped synthetic current_savings at income * 24\n",
            "[use] applied 'desired_savings' as goal for 0 rows\n",
            "[fix] 5300 label==0 & achievable_by_cutting -> setting monthly_saving_label = monthly_saving_required\n",
            "[save] wrote processed and features\n",
            "[audit] wrote problem_rows_zero_label.csv\n",
            "[save] wrote train/test\n",
            "\n",
            "=== pipeline summary ===\n",
            "rows: 20000\n",
            "income range: 15000 - 500000\n",
            "avg monthly_saving_label: 2440\n",
            "goals achieved: 10648 (53.2%)\n",
            "fraction label==0: 49.25%\n",
            "difficulty counts:\n",
            " difficulty_bucket\n",
            "achieved                 10648\n",
            "hard                      3995\n",
            "moderate                  3631\n",
            "achievable_by_cutting     1231\n",
            "easy                       495\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Audit files: disposable_mismatch_debug.csv, problem_rows_zero_label.csv, potential_savings_suspicious.csv (if created)\n",
            "=== pipeline end ===\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "DATA_DIR = \"/content/data\"\n",
        "FULL_FEAT = DATA_DIR + \"/processed_finance_dataset_features.csv\"  # full file created by pipeline\n",
        "df = pd.read_csv(FULL_FEAT)\n",
        "\n",
        "print(\"Rows total:\", len(df))\n",
        "print(\"Difficulty counts:\\n\", df['difficulty_bucket'].value_counts())\n",
        "print(\"achievable_by_cutting fraction:\", df['achievable_by_cutting'].mean())\n",
        "print(\"goal_achieved fraction:\", df['goal_achieved'].mean())\n",
        "print(\"monthly_saving_label stats:\\n\", df['monthly_saving_label'].describe())\n",
        "\n",
        "# CLASSIFIER dataset (achievable_by_cutting)\n",
        "clf_df = df.copy()\n",
        "# choose features\n",
        "feature_cols = ['income','disposable_income','current_savings','total_potential_savings',\n",
        "                'expense_ratio','savings_rate','age','dependents','city_tier','occupation']\n",
        "# simple drop NA\n",
        "clf_df = clf_df.dropna(subset=['achievable_by_cutting'] + feature_cols)\n",
        "X = clf_df[feature_cols]\n",
        "y = clf_df['achievable_by_cutting']\n",
        "# train/test split (stratify)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "print(\"Classifier shapes:\", X_train.shape, X_test.shape)\n",
        "\n",
        "# REGRESSION dataset (predict monthly_saving_label) — exclude already achieved rows\n",
        "reg_df = df[df['goal_achieved'] == 0].copy()\n",
        "reg_df = reg_df[reg_df['monthly_saving_label'] > 0]  # only meaningful numeric targets\n",
        "print(\"Regression dataset size (non-achieved & label>0):\", len(reg_df))\n",
        "if len(reg_df) >= 200:  # minimal size sanity\n",
        "    Xr = reg_df[feature_cols]\n",
        "    yr = reg_df['monthly_saving_label']\n",
        "    Xr_train, Xr_test, yr_train, yr_test = train_test_split(Xr, yr, test_size=0.2, random_state=42)\n",
        "    print(\"Regressor shapes:\", Xr_train.shape, Xr_test.shape)\n",
        "else:\n",
        "    print(\"Warning: too few examples for regression; consider expanding dataset or relaxing filters.\")\n",
        "\n",
        "# Save splits\n",
        "X_train.assign(target=y_train).to_csv(DATA_DIR+\"/clf_train.csv\", index=False)\n",
        "X_test.assign(target=y_test).to_csv(DATA_DIR+\"/clf_test.csv\", index=False)\n",
        "if len(reg_df) >= 200:\n",
        "    Xr_train.assign(target=yr_train).to_csv(DATA_DIR+\"/reg_train.csv\", index=False)\n",
        "    Xr_test.assign(target=yr_test).to_csv(DATA_DIR+\"/reg_test.csv\", index=False)\n",
        "\n",
        "print(\"Saved clf/reg splits to\", DATA_DIR)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OqYHOHEqo67B",
        "outputId": "78afd725-295c-49cf-88b5-d4672bd09009"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rows total: 20000\n",
            "Difficulty counts:\n",
            " difficulty_bucket\n",
            "achieved                 10648\n",
            "hard                      3995\n",
            "moderate                  3631\n",
            "achievable_by_cutting     1231\n",
            "easy                       495\n",
            "Name: count, dtype: int64\n",
            "achievable_by_cutting fraction: 0.32655\n",
            "goal_achieved fraction: 0.5324\n",
            "monthly_saving_label stats:\n",
            " count    20000.000000\n",
            "mean      2440.178019\n",
            "std       4326.414275\n",
            "min          0.000000\n",
            "25%          0.000000\n",
            "50%        136.657356\n",
            "75%       3309.913526\n",
            "max      84640.655113\n",
            "Name: monthly_saving_label, dtype: float64\n",
            "Classifier shapes: (16000, 10) (4000, 10)\n",
            "Regression dataset size (non-achieved & label>0): 9344\n",
            "Regressor shapes: (7475, 10) (1869, 10)\n",
            "Saved clf/reg splits to /content/data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "import joblib\n",
        "\n",
        "# -------------------------\n",
        "# 1. Load dataset\n",
        "# -------------------------\n",
        "df = pd.read_csv(\"/content/data/processed_finance_dataset.csv\")\n",
        "print(\"Full dataset shape:\", df.shape)\n",
        "print(\"Columns:\", df.columns.tolist())\n",
        "\n",
        "# -------------------------\n",
        "# 2. Define target\n",
        "# -------------------------\n",
        "target_col = \"achievable_by_cutting\"\n",
        "\n",
        "# Define safe features dynamically\n",
        "drop_leakage = [\n",
        "    target_col, \"goal_achieved\", \"monthly_saving_label\", \"monthly_saving_required\",\n",
        "    \"max_feasible_monthly_saving\", \"current_savings\", \"disposable_income\",\n",
        "    \"difficulty_bucket\", \"label_zero_reason\"\n",
        "]\n",
        "\n",
        "safe_features = [c for c in df.columns if c not in drop_leakage]\n",
        "print(\"Using features:\", safe_features)\n",
        "\n",
        "X = df[safe_features]\n",
        "y = df[target_col]\n",
        "\n",
        "# -------------------------\n",
        "# 3. Split train/test\n",
        "# -------------------------\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "print(\"Train shape:\", X_train.shape, \"Test shape:\", X_test.shape)\n",
        "\n",
        "# -------------------------\n",
        "# 4. Preprocessing\n",
        "# -------------------------\n",
        "categorical = [c for c in X.columns if df[c].dtype == \"object\"]\n",
        "numeric = [c for c in X.columns if c not in categorical]\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", StandardScaler(), numeric),\n",
        "        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), categorical)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# -------------------------\n",
        "# 5. Model\n",
        "# -------------------------\n",
        "pipeline = Pipeline(steps=[\n",
        "    (\"preprocessor\", preprocessor),\n",
        "    (\"clf\", XGBClassifier(\n",
        "        n_estimators=300,\n",
        "        learning_rate=0.05,\n",
        "        max_depth=6,\n",
        "        subsample=0.8,\n",
        "        colsample_bytree=0.8,\n",
        "        random_state=42,\n",
        "        use_label_encoder=False,\n",
        "        eval_metric=\"logloss\"\n",
        "    ))\n",
        "])\n",
        "\n",
        "# -------------------------\n",
        "# 6. Train\n",
        "# -------------------------\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "# -------------------------\n",
        "# 7. Evaluate\n",
        "# -------------------------\n",
        "y_pred = pipeline.predict(X_test)\n",
        "\n",
        "print(\"\\n=== Classification Report ===\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "\n",
        "# -------------------------\n",
        "# 8. Save model\n",
        "# -------------------------\n",
        "joblib.dump(pipeline, \"/content/savings_goal_clf.pkl\")\n",
        "print(\"Saved model to /content/savings_goal_clf.pkl\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNQDzhyypZ5L",
        "outputId": "c44eece9-f045-4b02-f933-0714dfe812e7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Full dataset shape: (20000, 26)\n",
            "Columns: ['income', 'total_expenses', 'disposable_income', 'current_savings', 'goal_target_amount', 'months_remaining', 'monthly_saving_label', 'monthly_saving_required', 'max_feasible_monthly_saving', 'monthly_saving_label_raw', 'expense_ratio', 'savings_rate', 'financial_health_score', 'goal_achieved', 'total_potential_savings', 'achievable_by_cutting', 'suggested_monthly_plan', 'difficulty_bucket', 'savings_is_synthetic', 'age', 'dependents', 'occupation', 'city_tier', 'education', 'desired_savings_percentage', 'potential_savings_education']\n",
            "Using features: ['income', 'total_expenses', 'goal_target_amount', 'months_remaining', 'monthly_saving_label_raw', 'expense_ratio', 'savings_rate', 'financial_health_score', 'total_potential_savings', 'suggested_monthly_plan', 'savings_is_synthetic', 'age', 'dependents', 'occupation', 'city_tier', 'education', 'desired_savings_percentage', 'potential_savings_education']\n",
            "Train shape: (16000, 18) Test shape: (4000, 18)\n",
            "\n",
            "=== Classification Report ===\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.96      0.94      2694\n",
            "           1       0.91      0.85      0.88      1306\n",
            "\n",
            "    accuracy                           0.92      4000\n",
            "   macro avg       0.92      0.90      0.91      4000\n",
            "weighted avg       0.92      0.92      0.92      4000\n",
            "\n",
            "Confusion Matrix:\n",
            " [[2586  108]\n",
            " [ 197 1109]]\n",
            "Accuracy: 0.92375\n",
            "Saved model to /content/savings_goal_clf.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import pandas as pd\n",
        "import google.generativeai as genai\n",
        "import joblib\n",
        "from google.colab import userdata # Import userdata\n",
        "\n",
        "# ----------------------------\n",
        "# 1. Load the trained model\n",
        "# ----------------------------\n",
        "# Use joblib.load instead of pickle.load directly\n",
        "with open(\"/content/savings_goal_clf.pkl\", \"rb\") as f:\n",
        "    model = joblib.load(f)\n",
        "\n",
        "# Define the same feature order used in training\n",
        "FEATURES = [\n",
        "    'income', 'total_expenses', 'goal_target_amount', 'months_remaining',\n",
        "    'monthly_saving_label_raw', 'expense_ratio', 'savings_rate',\n",
        "    'financial_health_score', 'total_potential_savings',\n",
        "    'suggested_monthly_plan', 'savings_is_synthetic', 'age', 'dependents',\n",
        "    'occupation', 'city_tier', 'education', 'desired_savings_percentage',\n",
        "    'potential_savings_education'\n",
        "]\n",
        "\n",
        "# ----------------------------\n",
        "# 2. Example user input\n",
        "# ----------------------------\n",
        "user_input = {\n",
        "    \"income\": 40000,\n",
        "    \"total_expenses\": 32000,\n",
        "    \"goal_target_amount\": 150000,\n",
        "    \"months_remaining\": 24,\n",
        "    \"monthly_saving_label_raw\": 2000,\n",
        "    \"expense_ratio\": 0.8,\n",
        "    \"savings_rate\": 0.05,\n",
        "    \"financial_health_score\": 2, # Assuming this is a placeholder or needs calculation\n",
        "    \"total_potential_savings\": 5000,\n",
        "    \"suggested_monthly_plan\": 2500,\n",
        "    \"savings_is_synthetic\": 0,\n",
        "    \"age\": 30,\n",
        "    \"dependents\": 2,\n",
        "    \"occupation\": \"Professional\",\n",
        "    \"city_tier\": \"Tier_2\",\n",
        "    \"education\": 16, # Assuming this is years of education or a categorical encoding\n",
        "    \"desired_savings_percentage\": 15,\n",
        "    \"potential_savings_education\": 500 # Assuming this is a monetary value\n",
        "}\n",
        "\n",
        "# Wrap input in DataFrame (1-row, same order of features)\n",
        "input_df = pd.DataFrame([user_input], columns=FEATURES)\n",
        "\n",
        "# ----------------------------\n",
        "# 3. Run prediction\n",
        "# ----------------------------\n",
        "prediction = model.predict(input_df)[0]\n",
        "proba = model.predict_proba(input_df)[0][1]\n",
        "\n",
        "print(f\"Prediction: {prediction} (probability of achievable_by_cutting={proba:.2f})\")\n",
        "\n",
        "# ----------------------------\n",
        "# 4. Setup Gemini API\n",
        "# ----------------------------\n",
        "# Use userdata.get to retrieve the API key from Colab Secrets\n",
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "\n",
        "\n",
        "model_gemini = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "\n",
        "# Construct a structured prompt\n",
        "prompt = f\"\"\"\n",
        "You are a financial advisor AI. Interpret the following user financial profile and\n",
        "the ML model's prediction about whether they can achieve their savings goal by cutting expenses.\n",
        "\n",
        "User profile:\n",
        "{user_input}\n",
        "\n",
        "ML Prediction:\n",
        "- Achievable by cutting: {bool(prediction)}\n",
        "- Confidence: {proba:.2f}\n",
        "\n",
        "Please provide:\n",
        "1. A short plain-language explanation of the prediction.\n",
        "2. Practical savings or expense adjustment advice tailored to the profile.\n",
        "\"\"\"\n",
        "\n",
        "# ----------------------------\n",
        "# 5. Get insights from Gemini\n",
        "# ----------------------------\n",
        "response = model_gemini.generate_content(prompt)\n",
        "\n",
        "print(\"\\n=== Gemini Insights ===\")\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 511
        },
        "id": "T7Qomwakp5_g",
        "outputId": "b8dcac80-351d-47ad-f360-72ddd785b203"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: 1 (probability of achievable_by_cutting=0.99)\n",
            "\n",
            "=== Gemini Insights ===\n",
            "1. **Plain-Language Explanation:**\n",
            "\n",
            "The AI model predicts with very high confidence (99%) that you can reach your savings goal of $150,000 within 24 months by cutting expenses.  Your current savings rate is low, but the model believes that by making reasonable adjustments to your spending, you can significantly increase your savings and meet your target.\n",
            "\n",
            "2. **Practical Savings & Expense Adjustment Advice:**\n",
            "\n",
            "The model suggests a monthly savings plan of $2500.  This is achievable, given your current $8000 surplus ($40,000 income - $32,000 expenses), even though a significant portion of that is currently consumed by your monthly expenses. To reach your goal, here's a step-by-step approach focusing on realistic and practical adjustments:\n",
            "\n",
            "* **Analyze Spending:**  Carefully track your expenses for at least a month, categorizing everything.  This will highlight areas for potential reductions. Look for subscriptions you don't need, areas of overspending (e.g., dining out, entertainment), and potential savings on utilities (e.g., switching energy providers).\n",
            "\n",
            "* **Prioritize Essential Expenses:** Given you have two dependents, prioritize essential expenses (housing, food, healthcare, childcare).  Explore ways to reduce costs in these areas if possible (e.g., negotiating lower rent, cheaper grocery options, utilizing affordable childcare programs).\n",
            "\n",
            "* **Reduce Non-Essential Expenses:** This is where you'll find the most significant savings potential.  Look at entertainment, dining out, shopping, subscriptions, and travel.  Cutting back gradually and strategically will be more sustainable than drastic changes.  For example, limit dining out to once a week instead of multiple times, explore free or low-cost entertainment options, and cancel unnecessary subscriptions.\n",
            "\n",
            "* **Explore Potential Savings Education:** You have $500 identified for potential savings from education (presumably continuing education or skill development).  This is a smart investment; upskilling can lead to higher income in the future, further enhancing your savings capacity.\n",
            "\n",
            "* **Realistic Budgeting:** Aim for a monthly savings of at least $2500.  This requires a reduction of approximately $2500 in current spending.  Don't try to cut everything at once.  Start with smaller, manageable adjustments and gradually increase savings as you adapt. Consider using budgeting apps to track progress and stay motivated.\n",
            "\n",
            "* **Emergency Fund:** Before aggressively pursuing your savings goal, ensure you have a small emergency fund (e.g., 3-6 months of essential expenses) to cover unexpected events.  This prevents setbacks and maintains financial stability.\n",
            "\n",
            "\n",
            "**Important Note:** While the model is highly confident, it's a prediction, not a guarantee. Unexpected expenses can always occur.  Regularly review your budget and make adjustments as needed. Consider seeking professional financial advice from a human advisor to further personalize this plan.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_96eYVk-sUOo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}